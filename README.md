# Agentic RAG Streamlit Application

This project implements an Retrieval-Augmented Generation (RAG) system using **Gemini** and **Streamlit**. It allows users to ingest data from PDF files and web URLs, ask questions, and receive answers generated by a **Large Language Model (LLM)** leveraging the ingested context and optional web search results.
![architecture ](./assets/architecture.jpg)

### How it works

* The user uploads PDF documents or provides web URLs, these documents are processed and stored in **Chroma** Vector Database.
* The user submits a query, the query is first sent to a **Rewrite Agent**. This agent analyzes and reformulates the original query, aiming to improve its clarity and effectiveness for retrieval.
* The rewritten query is forwarded to the LLM. The LLM searches the Vector DB (**Chroma**), retrieving relevant text chunks based on semantic similarity. Simultaneously or based on configuration, it can leverage Web Search (**DuckDuckGo**) to gather information not present in the uploaded documents. If no specific context found, the LLM answers based on its general knowledge.
* The generated Response is sent back to the Streamlit interface, where it is displayed to the user.

## Features

* **Data Ingestion:** Upload PDF files or enter web URLs to populate the knowledge base.
* **Persistent Vector Store:** Uses **ChromaDB** to store and retrieve text embeddings locally.
* **Query Rewriting:** Employs an agent with **Agno** to reformulate user questions for potentially better retrieval results.
* **Retrieval-Augmented Generation (RAG):**
    * Retrieves relevant text chunks from the **ChromaDB** vector store based on the (rewritten) query.
    * Uses a RAG agent (**Gemini**) to synthesize an answer based on the retrieved context.
* **Web Search:** Optionally performs a web search via **DuckDuckGo** if:
    * No relevant documents are found in the local vector store.
    * Web search is explicitly forced via the UI.
* **Configuration:** Allows users to configure:
    * Enabling/disabling web search.
    * Forcing web search.
    * Adjusting the similarity score threshold for document retrieval.
* **Database Management:** Options to clear chat history and the vector database.
* **Dockerized:** Includes a `Dockerfile` for easy containerization and deployment.

## Tech Stack

* **Web Framework:** Streamlit
* **Vector Database:** ChromaDB
* **LLM & Embeddings:** Gemini
* **Core Logic:** Langchain (for document processing, vector store integration), Agno (for agents)
* **Containerization:** Docker

## Prerequisites

* **Python:** Version 3.11 or higher recommended.
* **pip:** Python package installer.
* **Git:** For cloning the repository.
* **Docker:** Required for running the application using Docker (recommended for easy setup and persistence).
* **Google API Key:** You need an API key for Google Generative AI (e.g., Gemini API). You can obtain one from [Google AI Studio](https://aistudio.google.com/app/apikey).

## How to use

1.  **Clone the Repository:**
    ```bash
    git clone <your-repository-url>
    cd <repository-directory>
    ```

2.  **Create a Virtual Environment (Recommended):**
    ```bash
    python -m venv venv
    # Activate it (Linux/macOS)
    source venv/bin/activate
    # Activate it (Windows)
    .\venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set Up Environment Variables:**
    * Create a file named `.env` in the project's root directory.
    * Copy the contents of `.env.example` (if provided) or add the following variables:

        ```dotenv
        # .env file
        GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
        COLLECTION_NAME="rag_system" # Or your preferred ChromaDB collection name (must follow ChromaDB rules)

        # --- Optional: Required only for Web Search feature ---
        # TAVILY_API_KEY="YOUR_TAVILY_API_KEY"
        ```
    * Replace `"YOUR_GOOGLE_API_KEY"` with your actual Google API key.
    * Replace `"YOUR_TAVILY_API_KEY"` if you plan to use the web search feature.

## Running the Application

You can run the application either directly using Streamlit or via Docker.

### 1. Running Locally

```bash
streamlit run app.py